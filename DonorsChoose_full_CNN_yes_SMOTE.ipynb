{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\nimport os\n\n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "023d9a4e-4124-486c-a1e1-21959abe638c",
        "_uuid": "e6c9ad8fc7678be212f9f156c72f9064dbb99553",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_test_dtypes = {'id':str, 'teacher_id':str, 'teacher_prefix':str, 'school_state':str, 'project_submitted_datetime':str, 'project_grade_category':str, 'project_subject_categories':str,\n                     'project_subject_subcategories':str, 'project_title':str, 'project_essay_1':str, 'project_essay_2':str, 'project_essay_3':str, 'project_essay_4':str, 'project_resource_summary':str, \n                     'teacher_number_of_previously_posted_projects':int, 'project_is_approved':int}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_data_raw = pd.read_csv('../input/donorschoose-application-screening/train.csv', sep=',', dtype=train_test_dtypes, low_memory=True)\ntest_data_raw = pd.read_csv('../input/donorschoose-application-screening/test.csv', sep=',', dtype=train_test_dtypes, low_memory=True)\nresource_data_raw = pd.read_csv('../input/donorschoose-application-screening/resources.csv', sep=',')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "419b0ca988b17df5ce77f99555a56c11bf1c32e0",
        "_cell_guid": "23f207f6-14d4-4c8f-bbf3-77b94e7b08f5"
      },
      "cell_type": "markdown",
      "source": "Change the project_submitted_datetime column to type datetime64, and extract year, month, and day as new features"
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "5ce6b930-c57e-4b78-8b7f-c783b30f0bd7",
        "_uuid": "657a4f77f98e390f475f2f1b540aba44db6e972f",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_data_raw['year'] = train_data_raw.project_submitted_datetime.apply(lambda x: x.split(\"-\")[0])\ntrain_data_raw['month'] = train_data_raw.project_submitted_datetime.apply(lambda x: x.split(\"-\")[1])\ntrain_data_raw['day'] = train_data_raw.project_submitted_datetime.apply(lambda x: x.split(\"-\")[2])\ntrain_data_raw['day'] = train_data_raw.day.apply(lambda x: x.split(\" \")[0])\ntrain_data_raw['project_submitted_datetime'] = pd.to_datetime(train_data_raw['project_submitted_datetime'], format=\"%Y-%m-%d %H:%M:%S\")\ntest_data_raw['year'] = test_data_raw.project_submitted_datetime.apply(lambda x: x.split(\"-\")[0])\ntest_data_raw['month'] = test_data_raw.project_submitted_datetime.apply(lambda x: x.split(\"-\")[1])\ntest_data_raw['day'] = test_data_raw.project_submitted_datetime.apply(lambda x: x.split(\"-\")[2])\ntest_data_raw['day'] = test_data_raw.day.apply(lambda x: x.split(\" \")[0])\ntest_data_raw['project_submitted_datetime'] = pd.to_datetime(test_data_raw['project_submitted_datetime'], format=\"%Y-%m-%d %H:%M:%S\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a3c5bbc0a0058e26dc1f665263839898c8f307eb",
        "_cell_guid": "962eadf7-3a83-4b2a-bd06-c01cff7bb58f"
      },
      "cell_type": "markdown",
      "source": "Create stats features based off of the quantity and price info in the resources dataset. Merge these into the training and test datasets"
    },
    {
      "metadata": {
        "_cell_guid": "73ba42d8-eb6a-48ee-baa1-0eb4d5a387f2",
        "_uuid": "00ab5224fa8bc63aed9a6bfce0a31a3d2eb6a781",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "resource_data_total = resource_data_raw.copy()\nresource_data_total['total'] = resource_data_total['quantity'] * resource_data_total['price']\nresource_data_total.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "11754ee8-f56a-4f59-ab1b-a3e57f40d08a",
        "_uuid": "4f0c603ab4f5699783746399a68c405ba2b6e2d7",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "res = resource_data_total[['id', 'total']].groupby('id').total.agg(\\\n    [\n        'count', \n        'sum', \n        'min', \n        'max', \n        'mean', \n        'median',\n        'std',\n    ]).reset_index()\nprint(res.head())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "c0f6d10f-831a-406f-9861-09b9676c940b",
        "_uuid": "15a5f892c77abb109ab7cc9e56efac25b02b995a",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_data_raw = train_data_raw.merge(res, on='id')\ntest_data_raw = test_data_raw.merge(res, on='id')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ff7a63c92e19c4e03174456271c5c3d4352d02d9",
        "_cell_guid": "8ad9474d-c766-4f04-badc-622bfe6c38fd"
      },
      "cell_type": "markdown",
      "source": "Some descriptions of items were NAN, these can be replaced with empty strings."
    },
    {
      "metadata": {
        "_cell_guid": "d5f93f34-cf23-490a-b7f3-92b891d3b8f9",
        "_uuid": "c109030071ed2f73477cdfbddaa7555b07c0de1e",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "resource_dropped = resource_data_raw.fillna('')\nresource_dropped.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d879b925e07133d7d51eee2ab6e70ef79cbf413a",
        "_cell_guid": "687c7014-92db-4ee1-83d2-6790620591ad"
      },
      "cell_type": "markdown",
      "source": "Create a pivot_table that joins all of the resources descriptions together by proposal id, then merge these combined descriptions into the training and test datasets."
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "8dd96347-c74a-4380-9e66-0687e39abf58",
        "_uuid": "67387dca8c43cc8e3a92c3f82e7790986650f048",
        "trusted": false
      },
      "cell_type": "code",
      "source": "pivot_table = resource_dropped.groupby('id').description.apply(lambda x: \"%s\" % ';'.join(x)).reset_index()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "8a1222b4-4ab4-40aa-adce-183dc393d119",
        "_uuid": "f1324e9bfc144edd92d19f8c1100f890725383fb",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_data_raw = train_data_raw.merge(pivot_table, on='id')\ntest_data_raw = test_data_raw.merge(pivot_table, on='id')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2848b7c1aa147e6a809dc2bf6d67e31d331d95c7",
        "_cell_guid": "a8dc93d3-820f-476f-8243-09c69913d624"
      },
      "cell_type": "markdown",
      "source": "Some STDDEV values were NAN, replace these with 0.0"
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "d0e90b46-9dc2-45e9-92f9-518bf986e793",
        "_uuid": "6a2d706bed88df318dc05e90deee0fdbfe27e279",
        "trusted": false
      },
      "cell_type": "code",
      "source": "values = {'std': 0.0}\ntrain_data_raw.fillna(value=values, inplace=True)\ntest_data_raw.fillna(value=values, inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "fc19244e-8c36-4e86-a120-4641e9829a78",
        "_uuid": "d553e34a14af3bc08ba5cbbb4da934b349d6904f"
      },
      "cell_type": "markdown",
      "source": "For earlier proposals, there were 4 essay questions instead of 2. For these, combine 1&2 as essay 1, and 3&4 as essay 2. Then remove essay 3 & 4 columns from the dataframe"
    },
    {
      "metadata": {
        "collapsed": true,
        "scrolled": true,
        "_cell_guid": "93a8ad51-047a-4cd0-b2d9-0a37f608d4db",
        "_uuid": "5c1b1a4767469f00bf28cf65d20b9432abca5f62",
        "trusted": false
      },
      "cell_type": "code",
      "source": "essay_3_4_nonull_filter = train_data_raw.project_essay_3.notnull()\n\ntrain_data_raw.loc[essay_3_4_nonull_filter,'project_essay_1'] = train_data_raw[essay_3_4_nonull_filter].project_essay_1.str.cat(train_data_raw[essay_3_4_nonull_filter].project_essay_2)\ntrain_data_raw.loc[essay_3_4_nonull_filter, 'project_essay_2'] = train_data_raw[essay_3_4_nonull_filter].project_essay_3.str.cat(train_data_raw[essay_3_4_nonull_filter].project_essay_4)\n\ntrain_data_raw.drop(['project_essay_3', 'project_essay_4'], axis=1, inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "123f3dc9-131c-44f5-a19e-a5117d5e891d",
        "_uuid": "0e6e17e760dda2a2bf1b6ae79d31988d8e75f666"
      },
      "cell_type": "markdown",
      "source": "Drop remaining 4 rows in training dataset which have Null values (in teacher_prefix)"
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "3d39574b-ccaf-47ec-abc3-a4a6869029df",
        "_uuid": "1d07a2d097abb8a5e4e85eebb74c67c4e437f70e",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_data_raw[pd.isnull(train_data_raw).any(axis=1)]\ntrain_data_raw.dropna(inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "88fa9d79-b66d-4581-b6ef-0ac8b57dc0ea",
        "_uuid": "4b1a9ba6540d937b186fca96c45d1a78fb200165",
        "trusted": false
      },
      "cell_type": "code",
      "source": "test_essay_3_4_nonull_filter = test_data_raw.project_essay_3.notnull()\n\ntest_data_raw.loc[test_essay_3_4_nonull_filter,'project_essay_1'] = test_data_raw[test_essay_3_4_nonull_filter].project_essay_1.str.cat(test_data_raw[test_essay_3_4_nonull_filter].project_essay_2)\ntest_data_raw.loc[test_essay_3_4_nonull_filter, 'project_essay_2'] = test_data_raw[test_essay_3_4_nonull_filter].project_essay_3.str.cat(test_data_raw[test_essay_3_4_nonull_filter].project_essay_4)\n\ntest_data_raw.drop(['project_essay_3', 'project_essay_4'], axis=1, inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "28a88c60e95bd14dcd89d731430a71b420db26b1",
        "_cell_guid": "1656dc2c-2ffe-403b-95a6-aa45175931a2"
      },
      "cell_type": "markdown",
      "source": "The test dataset has one NAN value for teacher_prefix. Replace with NAN with \"Teacher\""
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "e713ad56-4f94-480e-932b-e744d40388fb",
        "_uuid": "ee9f1584b81cbff11a95109fe4343e51c236fbb6",
        "trusted": false
      },
      "cell_type": "code",
      "source": "test_data_raw.fillna(value=\"Teacher\", inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f03e1225dd172981054bbf777f737fb1dae06816",
        "_cell_guid": "60922524-75c3-48aa-8e7f-f51df044240e"
      },
      "cell_type": "markdown",
      "source": "Scale the numeric data "
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "b5a298ea-c8d6-4e3a-b102-b96ba7f41b46",
        "_uuid": "a9409362fa74811c731c3242ee2a6386486869bb",
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import StandardScaler\n\nnum_features = ['teacher_number_of_previously_posted_projects', 'count', 'sum', 'min', 'max', 'mean', 'median', 'std']\nscalar = StandardScaler()\nX_train_num = scalar.fit_transform(train_data_raw[num_features])\nX_test_num = scalar.fit_transform(test_data_raw[num_features])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ee7780463aa2eb9438ed5787b8c0e7832ab4e547",
        "_cell_guid": "8065f969-8302-43fc-b5b3-592b4d6951fc"
      },
      "cell_type": "markdown",
      "source": "Create new hash features from the categorical data"
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "5fe465a2-7b67-4879-b30f-387f24ce5b84",
        "_uuid": "df58ff06c94a857bc74fe9ca137d53415a860cc9",
        "trusted": false
      },
      "cell_type": "code",
      "source": "cat_features = ['project_grade_category', 'project_subject_categories', 'project_subject_subcategories', 'teacher_prefix', 'school_state','year','month','day']\ncat_features_hash = [col+\"_hash\" for col in cat_features]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "6e771fbe-baaa-4045-8fa7-1c8a3bcc87fa",
        "_uuid": "bcb7908b9ff75077846153b0af91093f86a6e627",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#create new categorical hash features\nmax_size=1501\ndef feature_hash(df, max_size=max_size):\n    for col in cat_features:\n        df[col+\"_hash\"] = df[col].apply(lambda x: (hash(x)%(max_size-1)+1))\n    return df\n\ntrain_data_raw = feature_hash(train_data_raw)\ntest_data_raw = feature_hash(test_data_raw)\nX_train_cat = np.array(train_data_raw[cat_features_hash], dtype=np.int)\nX_test_cat = np.array(test_data_raw[cat_features_hash], dtype=np.int)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "a9a92832-b5c4-4a20-aa82-6d51ea53595f",
        "_uuid": "01e1dacbc2cc63a3d9af3750e4ba489c3998674a",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# concatenate all of the text fields together as a new 'text' feature\ntext_features_final = ['project_title', 'project_essay_1', 'project_essay_2', 'project_resource_summary', 'description']\n\ntrain_data_raw['text'] = train_data_raw.apply(lambda x: \" \".join(x[col] for col in text_features_final), axis=1)\ntest_data_raw['text'] = test_data_raw.apply(lambda x: \" \".join(x[col] for col in text_features_final), axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4567f7f20832c46a0b5af9ad0b7d45121d81f7bd",
        "_cell_guid": "f470f65b-bd7d-42e1-b7b9-e652dea16b3e"
      },
      "cell_type": "markdown",
      "source": "Tokenize the training text data"
    },
    {
      "metadata": {
        "_cell_guid": "a63a0dc2-0c37-4e86-8998-503c98a22034",
        "_uuid": "8af0b7ea9c9b3ae0099fb8ebe972c0b29b394c19",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "EMBEDDING_DIM = 300\nmax_features = 50000\n\nt = Tokenizer(num_words=max_features)\nt.fit_on_texts(train_data_raw['text'].tolist() + test_data_raw['text'].tolist())\nsequences = t.texts_to_sequences(train_data_raw['text'])\n\nword_index = t.word_index\nprint('Found %s unique tokens.' % len(word_index))\n\nX_train_word = pad_sequences(sequences, maxlen=EMBEDDING_DIM)\ny_train = train_data_raw.project_is_approved",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9fc93e2e13de2c927ef0124b138aeb1914067c23",
        "_cell_guid": "bf2eb64e-5add-43fb-b251-c2bced2d3a3f"
      },
      "cell_type": "markdown",
      "source": "Split off 10% of the training data as a validation set"
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "02699c7f-9a4b-4c16-bb6e-8f4c58ebff76",
        "_uuid": "9975d550b347aa9efee32df07dc99fcfe784052a",
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\nX_train_num_split, X_val_num, y_train_num_split, y_val_num = train_test_split(X_train_num, y_train, test_size=.1, shuffle=False)\nX_train_cat_split, X_val_cat, y_train_cat_split, y_val_cat = train_test_split(X_train_cat, y_train, test_size=.1, shuffle=False)\nX_train_word_split, X_val_word, y_train_word_split, y_val_word = train_test_split(X_train_word, y_train, test_size=.1, shuffle=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "848bdce31a86089f4b0cb69387e8f6424ce4566c",
        "_cell_guid": "28602bde-ec57-41bf-844b-5a4acc15a4f7"
      },
      "cell_type": "markdown",
      "source": "Oversample the minority data"
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "1bdc1351-3d19-4bbb-bc4c-8ba0cce0ac5f",
        "_uuid": "e020a447fd7e6bb3fc5fc1ab9a6fd8a12d3eb3ce",
        "trusted": false
      },
      "cell_type": "code",
      "source": "from imblearn.over_sampling import SMOTE\n\nsm = SMOTE(random_state=42)\nX_train_num_smote, y_train_num_smote = sm.fit_sample(X_train_num_split, y_train_num_split)\nX_train_word_smote, y_train_word_smote = sm.fit_sample(X_train_word_split, y_train_word_split)\nX_train_cat_smote, y_train_cat_smote = sm.fit_sample(X_train_cat_split, y_train_cat_split)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5116536f9b80149465df2e211b6bfaa33053d2bb",
        "_cell_guid": "caafa41c-f0ac-4b90-b0db-c45419ef1689"
      },
      "cell_type": "markdown",
      "source": "Use pre-trained embeddings"
    },
    {
      "metadata": {
        "_cell_guid": "3f43e90b-90ab-4883-af92-42d64a7b5aca",
        "_uuid": "ed356618ad21f923d2bebbd6ed05c7182d1bb59f",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#GLOVE_DIR = '../input/glove-global-vectors-for-word-representation'\nFASTTEXT_DIR = '../input/fatsttext-common-crawl/crawl-300d-2M'\nembeddings_index = {}\n#f = open(os.path.join(GLOVE_DIR, 'glove.6B.200d.txt'))\nf = open(os.path.join(FASTTEXT_DIR, 'crawl-300d-2M.vec'))\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\n\nprint('Found %s word vectors.' % len(embeddings_index))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "1a93b248-ca54-4f08-923f-b43927b0903e",
        "_uuid": "0dd9de6b40a7dce19eb18a043d78c5ee0ea56fb7",
        "trusted": false
      },
      "cell_type": "code",
      "source": "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        # words not found in embedding index will be all-zeros.\n        embedding_matrix[i] = embedding_vector",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "57d44190-3504-4c23-8d2e-958a5ed0e3b8",
        "_uuid": "799d4f8a9fc67d15c9a0b37e6575b341ab58b611",
        "trusted": false
      },
      "cell_type": "code",
      "source": "from keras.layers import Embedding, Input, Dense, Conv1D, MaxPooling1D, Flatten, GlobalMaxPool1D, Dropout, Convolution1D, Bidirectional, GRU, SpatialDropout1D, concatenate\nfrom keras.models import Model, Sequential\nfrom keras import optimizers\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom sklearn.metrics import roc_auc_score",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "27303628-85c4-483f-bfeb-63efe3bc2c97",
        "_uuid": "c43259314cefc7e4f427bf08e4effe48c65633c9",
        "trusted": false
      },
      "cell_type": "code",
      "source": "def get_deep_num_cat_words_model():\n    input_words = Input((EMBEDDING_DIM, ))\n    input_cat = Input((len(cat_features_hash), ))\n    input_num = Input((len(num_features),))\n    \n    x_cat = Embedding(max_size, 10)(input_cat)\n    x_cat = SpatialDropout1D(0.3)(x_cat)\n    x_cat = Flatten()(x_cat)\n    x_cat = Dense(50, activation='relu')(x_cat)\n    x_cat = Dropout(0.25)(x_cat)\n    x_cat = Dense(100, activation=\"relu\")(x_cat)\n    \n    x_words = Embedding(len(word_index) + 1, EMBEDDING_DIM,\n                            weights=[embedding_matrix],\n                            trainable=False)(input_words)\n    x_words = SpatialDropout1D(0.3)(x_words)\n    x_words = Bidirectional(GRU(50, return_sequences=True))(x_words)\n    x_words = Convolution1D(100, 3, activation=\"relu\")(x_words)\n    x_words = GlobalMaxPool1D()(x_words)\n    \n    x_num = Dense(100, activation='relu')(input_num)\n    x_num = Dropout(0.3)(x_num)\n    x_num = Dense(100, activation='relu')(x_num)\n    x_num = Dropout(0.3)(x_num)\n    \n    x = concatenate([x_cat, x_num, x_words])\n    x = Dense(50, activation=\"relu\")(x)\n    x = Dropout(0.25)(x)\n    predictions = Dense(1, activation=\"sigmoid\")(x)\n    model = Model(inputs=[input_cat, input_num, input_words], outputs=predictions)\n    model.compile(optimizer=optimizers.Adam(0.0005, decay=1e-6),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n    #model.summary()\n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d211a2d70b3c07ad054028d929aa0aca6c55eab8",
        "_cell_guid": "51930fcc-93f1-4e53-9ce0-5f8ff8825bec"
      },
      "cell_type": "markdown",
      "source": "Instatiate the model, use ModelCheckpoint to save best weights"
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "75b51605-ad4e-43e1-be53-5d4cde79b3ea",
        "_uuid": "b70d959e1b7669d02ac6837b5831c121c3c7738e",
        "trusted": false
      },
      "cell_type": "code",
      "source": "deep_model = get_deep_num_cat_words_model()\ndeep_model_weight_filepath = \"deep_num_cat_words_weights.best.hdf5\"\ndeep_model_checkpoint = ModelCheckpoint(deep_model_weight_filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\nearly_stopping = EarlyStopping(monitor='val_loss', patience=2)\ndeep_model_callbacks_list = [deep_model_checkpoint, early_stopping]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "77642254b1c3e6e108714553aa86a188a4675d70",
        "_cell_guid": "dd01cc53-acec-4414-b35c-4c04cf50faa6"
      },
      "cell_type": "markdown",
      "source": "Train the model"
    },
    {
      "metadata": {
        "_cell_guid": "e243b0a0-741c-4b15-b40f-74292790a84f",
        "_uuid": "756c535be4c82753d9d2c4ca05c48e32765190d1",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "history = deep_model.fit([X_train_cat_smote, X_train_num_smote, X_train_word_smote], y_train_cat_smote, validation_split=0.1, epochs=4, batch_size=256, callbacks=deep_model_callbacks_list)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c66188c5be004a33a9cdd068bb2b69bf713b0c31",
        "_cell_guid": "23eecea3-2824-41f2-beb2-d881bf86a3a4"
      },
      "cell_type": "markdown",
      "source": "Load the best weights and make predictions on the validation set. Report the AUROC"
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "642f3584-fd55-4bd4-a27e-3d095c9dc777",
        "_uuid": "1c3259fbbb6fa701cb1d668e60e4391bdc6233d2",
        "trusted": false
      },
      "cell_type": "code",
      "source": "deep_model.load_weights(deep_model_weight_filepath)\ndeep_model_pred_val = deep_model.predict([X_val_cat, X_val_num, X_val_word], batch_size=2000)\n\ndeep_model_val_AUROC = roc_auc_score(y_val_cat, deep_model_pred_val)\nprint(\"deep_model_val_AUROC AUROC: {}\".format(deep_model_val_AUROC))\n\nAUROC_file = \"deep_model_val_AUROC.txt\"\nf = open(AUROC_file, \"w\")\nf.write(\"{}\".format(deep_model_val_AUROC))\nf.close()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "06d659c3f9f0fd591674a93f390ec8b2155e8719",
        "_cell_guid": "337cc2fa-669b-4a99-b720-291f04ebe91f"
      },
      "cell_type": "markdown",
      "source": "Make predictions on the Kaggle public test set and save to file so that they can be submitted to the competition."
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "2e3a593c-26ef-4883-8ee9-27bbf608d61c",
        "_uuid": "fce6a6342b3bbba7d484a2e6cd597e7a3a88d0e3",
        "trusted": false
      },
      "cell_type": "code",
      "source": "list_tokenized_test = t.texts_to_sequences(test_data_raw['text'].tolist())\nX_test_words = pad_sequences(list_tokenized_test, maxlen=EMBEDDING_DIM)\n\ndeep_model_pred_test = deep_model.predict([X_test_cat, X_test_num, X_test_words])\ntest_data_raw[\"project_is_approved\"] = deep_model_pred_test\ntest_data_raw[['id', 'project_is_approved']].to_csv(\"deep_model_fasttext300_fullSMOTE_submission.csv\", index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "24c619ad52880a5e1c4a4f15cae0428de893d849",
        "_cell_guid": "5f6bcfe9-614b-4a88-8bc6-f816faa65672",
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}